{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/czapata-ande/ai-frameworks/blob/main/iris_keras_6bloques_kappa_cm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJ_nimRNpsGh"
      },
      "source": [
        "# Clasificación del dataset Iris con Keras y TensorFlow\n",
        "## 1. CARGA DE DATOS"
      ],
      "id": "UJ_nimRNpsGh"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "3UJ8AR8hpsGi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Cargar el dataset iris\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "class_names = iris.target_names"
      ],
      "id": "3UJ8AR8hpsGi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azhO2xtspsGj"
      },
      "source": [
        "## 2. PREPROCESAMIENTO"
      ],
      "id": "azhO2xtspsGj"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "SUVf6hoPpsGj"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Escalar características\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# One-hot encoding para las clases\n",
        "y_categorical = to_categorical(y)\n",
        "\n",
        "# División en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_categorical, test_size=0.2, random_state=1912)"
      ],
      "id": "SUVf6hoPpsGj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwjQYh34psGj"
      },
      "source": [
        "## 3. CONSTRUCCIÓN DEL MODELO"
      ],
      "id": "iwjQYh34psGj"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C_Iz3hlpsGj",
        "outputId": "df47eb62-628c-4fef-c101-eb7e51d018ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Definir la arquitectura de la red neuronal\n",
        "model = Sequential([\n",
        "    Dense(12, activation='relu', input_shape=(X.shape[1],)),\n",
        "    Dense(6, activation='relu'),\n",
        "    Dense(3, activation='softmax')  # 3 clases\n",
        "])"
      ],
      "id": "-C_Iz3hlpsGj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2bKWWIGpsGj"
      },
      "source": [
        "## 4. COMPILACIÓN DEL MODELO"
      ],
      "id": "B2bKWWIGpsGj"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "JnQHBt1SpsGj"
      },
      "outputs": [],
      "source": [
        "# Compilar el modelo\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "id": "JnQHBt1SpsGj"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whz-ntakpsGk"
      },
      "source": [
        "## 5. ENTRENAMIENTO DEL MODELO"
      ],
      "id": "whz-ntakpsGk"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aqbRzeApsGk",
        "outputId": "209c5ec8-aae5-4947-8492-ab7f3d6d5de5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.5862 - loss: 0.9869 - val_accuracy: 0.7500 - val_loss: 0.7043\n",
            "Epoch 2/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5163 - loss: 0.9043 - val_accuracy: 0.7500 - val_loss: 0.6608\n",
            "Epoch 3/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6085 - loss: 0.8145 - val_accuracy: 0.7500 - val_loss: 0.6265\n",
            "Epoch 4/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6737 - loss: 0.8117 - val_accuracy: 0.7500 - val_loss: 0.6055\n",
            "Epoch 5/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6696 - loss: 0.8567 - val_accuracy: 0.7500 - val_loss: 0.5866\n",
            "Epoch 6/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7659 - loss: 0.7497 - val_accuracy: 0.7500 - val_loss: 0.5698\n",
            "Epoch 7/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8100 - loss: 0.6777 - val_accuracy: 0.7500 - val_loss: 0.5522\n",
            "Epoch 8/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8410 - loss: 0.6653 - val_accuracy: 0.7500 - val_loss: 0.5346\n",
            "Epoch 9/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7297 - loss: 0.7230 - val_accuracy: 0.7500 - val_loss: 0.5145\n",
            "Epoch 10/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8187 - loss: 0.5987 - val_accuracy: 0.7500 - val_loss: 0.4938\n",
            "Epoch 11/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7794 - loss: 0.6176 - val_accuracy: 0.7500 - val_loss: 0.4756\n",
            "Epoch 12/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7216 - loss: 0.6721 - val_accuracy: 0.7500 - val_loss: 0.4580\n",
            "Epoch 13/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7980 - loss: 0.5384 - val_accuracy: 0.7500 - val_loss: 0.4413\n",
            "Epoch 14/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8246 - loss: 0.5624 - val_accuracy: 0.7500 - val_loss: 0.4250\n",
            "Epoch 15/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8445 - loss: 0.4648 - val_accuracy: 0.7500 - val_loss: 0.4120\n",
            "Epoch 16/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8305 - loss: 0.5223 - val_accuracy: 0.7500 - val_loss: 0.3985\n",
            "Epoch 17/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8086 - loss: 0.4886 - val_accuracy: 0.7500 - val_loss: 0.3836\n",
            "Epoch 18/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8525 - loss: 0.4500 - val_accuracy: 0.7500 - val_loss: 0.3678\n",
            "Epoch 19/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8107 - loss: 0.4967 - val_accuracy: 0.7500 - val_loss: 0.3563\n",
            "Epoch 20/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8671 - loss: 0.3914 - val_accuracy: 0.8333 - val_loss: 0.3450\n",
            "Epoch 21/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8397 - loss: 0.3962 - val_accuracy: 0.8333 - val_loss: 0.3326\n",
            "Epoch 22/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8957 - loss: 0.3644 - val_accuracy: 0.8333 - val_loss: 0.3245\n",
            "Epoch 23/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8527 - loss: 0.3713 - val_accuracy: 0.8333 - val_loss: 0.3122\n",
            "Epoch 24/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8567 - loss: 0.3706 - val_accuracy: 0.8333 - val_loss: 0.3027\n",
            "Epoch 25/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8063 - loss: 0.3834 - val_accuracy: 0.8333 - val_loss: 0.2905\n",
            "Epoch 26/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7986 - loss: 0.3846 - val_accuracy: 0.8333 - val_loss: 0.2819\n",
            "Epoch 27/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8607 - loss: 0.3663 - val_accuracy: 0.8333 - val_loss: 0.2771\n",
            "Epoch 28/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8585 - loss: 0.3636 - val_accuracy: 0.8333 - val_loss: 0.2751\n",
            "Epoch 29/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8585 - loss: 0.3537 - val_accuracy: 0.8333 - val_loss: 0.2647\n",
            "Epoch 30/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8579 - loss: 0.3639 - val_accuracy: 0.8333 - val_loss: 0.2603\n",
            "Epoch 31/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8644 - loss: 0.3364 - val_accuracy: 0.8333 - val_loss: 0.2515\n",
            "Epoch 32/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8725 - loss: 0.2819 - val_accuracy: 0.8333 - val_loss: 0.2486\n",
            "Epoch 33/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8831 - loss: 0.3281 - val_accuracy: 0.8333 - val_loss: 0.2439\n",
            "Epoch 34/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8969 - loss: 0.3130 - val_accuracy: 0.8333 - val_loss: 0.2408\n",
            "Epoch 35/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9216 - loss: 0.2918 - val_accuracy: 0.8333 - val_loss: 0.2315\n",
            "Epoch 36/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9206 - loss: 0.2428 - val_accuracy: 0.8333 - val_loss: 0.2263\n",
            "Epoch 37/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8911 - loss: 0.2812 - val_accuracy: 0.8333 - val_loss: 0.2229\n",
            "Epoch 38/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8627 - loss: 0.2919 - val_accuracy: 0.8333 - val_loss: 0.2143\n",
            "Epoch 39/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9060 - loss: 0.2475 - val_accuracy: 0.8333 - val_loss: 0.2151\n",
            "Epoch 40/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9083 - loss: 0.2657 - val_accuracy: 0.8333 - val_loss: 0.2107\n",
            "Epoch 41/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8761 - loss: 0.2884 - val_accuracy: 0.8333 - val_loss: 0.2064\n",
            "Epoch 42/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8828 - loss: 0.2515 - val_accuracy: 0.8333 - val_loss: 0.2003\n",
            "Epoch 43/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9110 - loss: 0.2402 - val_accuracy: 0.8333 - val_loss: 0.1978\n",
            "Epoch 44/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8806 - loss: 0.2546 - val_accuracy: 0.9167 - val_loss: 0.1923\n",
            "Epoch 45/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9176 - loss: 0.2045 - val_accuracy: 1.0000 - val_loss: 0.1856\n",
            "Epoch 46/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9363 - loss: 0.1963 - val_accuracy: 1.0000 - val_loss: 0.1861\n",
            "Epoch 47/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9141 - loss: 0.2066 - val_accuracy: 1.0000 - val_loss: 0.1847\n",
            "Epoch 48/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9124 - loss: 0.2174 - val_accuracy: 1.0000 - val_loss: 0.1763\n",
            "Epoch 49/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9431 - loss: 0.2008 - val_accuracy: 1.0000 - val_loss: 0.1728\n",
            "Epoch 50/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9386 - loss: 0.1827 - val_accuracy: 1.0000 - val_loss: 0.1653\n",
            "Epoch 51/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9267 - loss: 0.2527 - val_accuracy: 1.0000 - val_loss: 0.1611\n",
            "Epoch 52/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9412 - loss: 0.1855 - val_accuracy: 1.0000 - val_loss: 0.1577\n",
            "Epoch 53/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9235 - loss: 0.2253 - val_accuracy: 1.0000 - val_loss: 0.1532\n",
            "Epoch 54/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9163 - loss: 0.2717 - val_accuracy: 1.0000 - val_loss: 0.1505\n",
            "Epoch 55/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9507 - loss: 0.1802 - val_accuracy: 1.0000 - val_loss: 0.1479\n",
            "Epoch 56/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9691 - loss: 0.1868 - val_accuracy: 1.0000 - val_loss: 0.1441\n",
            "Epoch 57/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9706 - loss: 0.1480 - val_accuracy: 1.0000 - val_loss: 0.1367\n",
            "Epoch 58/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9563 - loss: 0.1792 - val_accuracy: 1.0000 - val_loss: 0.1334\n",
            "Epoch 59/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.1474 - val_accuracy: 1.0000 - val_loss: 0.1286\n",
            "Epoch 60/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9803 - loss: 0.1567 - val_accuracy: 1.0000 - val_loss: 0.1261\n",
            "Epoch 61/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9512 - loss: 0.1765 - val_accuracy: 1.0000 - val_loss: 0.1234\n",
            "Epoch 62/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9765 - loss: 0.1472 - val_accuracy: 1.0000 - val_loss: 0.1218\n",
            "Epoch 63/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9685 - loss: 0.1571 - val_accuracy: 1.0000 - val_loss: 0.1203\n",
            "Epoch 64/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9445 - loss: 0.1614 - val_accuracy: 1.0000 - val_loss: 0.1165\n",
            "Epoch 65/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9659 - loss: 0.1512 - val_accuracy: 1.0000 - val_loss: 0.1134\n",
            "Epoch 66/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9382 - loss: 0.1533 - val_accuracy: 1.0000 - val_loss: 0.1083\n",
            "Epoch 67/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9331 - loss: 0.1754 - val_accuracy: 1.0000 - val_loss: 0.1068\n",
            "Epoch 68/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9655 - loss: 0.1432 - val_accuracy: 1.0000 - val_loss: 0.1051\n",
            "Epoch 69/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9454 - loss: 0.1489 - val_accuracy: 1.0000 - val_loss: 0.1015\n",
            "Epoch 70/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9769 - loss: 0.1208 - val_accuracy: 1.0000 - val_loss: 0.1004\n",
            "Epoch 71/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9697 - loss: 0.1085 - val_accuracy: 1.0000 - val_loss: 0.0958\n",
            "Epoch 72/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9464 - loss: 0.1400 - val_accuracy: 1.0000 - val_loss: 0.0946\n",
            "Epoch 73/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9593 - loss: 0.1053 - val_accuracy: 1.0000 - val_loss: 0.0928\n",
            "Epoch 74/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9863 - loss: 0.0961 - val_accuracy: 1.0000 - val_loss: 0.0915\n",
            "Epoch 75/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9714 - loss: 0.1143 - val_accuracy: 1.0000 - val_loss: 0.0875\n",
            "Epoch 76/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9527 - loss: 0.1272 - val_accuracy: 1.0000 - val_loss: 0.0866\n",
            "Epoch 77/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9649 - loss: 0.1065 - val_accuracy: 1.0000 - val_loss: 0.0848\n",
            "Epoch 78/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9280 - loss: 0.1306 - val_accuracy: 1.0000 - val_loss: 0.0825\n",
            "Epoch 79/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9769 - loss: 0.0963 - val_accuracy: 1.0000 - val_loss: 0.0806\n",
            "Epoch 80/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9751 - loss: 0.0910 - val_accuracy: 1.0000 - val_loss: 0.0792\n",
            "Epoch 81/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9690 - loss: 0.0957 - val_accuracy: 1.0000 - val_loss: 0.0774\n",
            "Epoch 82/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9616 - loss: 0.0974 - val_accuracy: 1.0000 - val_loss: 0.0759\n",
            "Epoch 83/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9894 - loss: 0.0782 - val_accuracy: 1.0000 - val_loss: 0.0748\n",
            "Epoch 84/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9793 - loss: 0.0997 - val_accuracy: 1.0000 - val_loss: 0.0738\n",
            "Epoch 85/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9765 - loss: 0.0997 - val_accuracy: 1.0000 - val_loss: 0.0727\n",
            "Epoch 86/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9824 - loss: 0.0853 - val_accuracy: 1.0000 - val_loss: 0.0719\n",
            "Epoch 87/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9494 - loss: 0.1131 - val_accuracy: 1.0000 - val_loss: 0.0703\n",
            "Epoch 88/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9826 - loss: 0.0947 - val_accuracy: 1.0000 - val_loss: 0.0689\n",
            "Epoch 89/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9631 - loss: 0.1035 - val_accuracy: 1.0000 - val_loss: 0.0672\n",
            "Epoch 90/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9731 - loss: 0.0801 - val_accuracy: 1.0000 - val_loss: 0.0659\n",
            "Epoch 91/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9830 - loss: 0.0811 - val_accuracy: 1.0000 - val_loss: 0.0655\n",
            "Epoch 92/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9768 - loss: 0.0745 - val_accuracy: 1.0000 - val_loss: 0.0646\n",
            "Epoch 93/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9874 - loss: 0.0697 - val_accuracy: 1.0000 - val_loss: 0.0636\n",
            "Epoch 94/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0800 - val_accuracy: 1.0000 - val_loss: 0.0625\n",
            "Epoch 95/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0657 - val_accuracy: 1.0000 - val_loss: 0.0608\n",
            "Epoch 96/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0788 - val_accuracy: 1.0000 - val_loss: 0.0593\n",
            "Epoch 97/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9825 - loss: 0.0698 - val_accuracy: 1.0000 - val_loss: 0.0592\n",
            "Epoch 98/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9687 - loss: 0.0861 - val_accuracy: 1.0000 - val_loss: 0.0581\n",
            "Epoch 99/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9700 - loss: 0.0794 - val_accuracy: 1.0000 - val_loss: 0.0573\n",
            "Epoch 100/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9685 - loss: 0.0805 - val_accuracy: 1.0000 - val_loss: 0.0565\n",
            "Epoch 101/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9739 - loss: 0.0732 - val_accuracy: 1.0000 - val_loss: 0.0556\n",
            "Epoch 102/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9877 - loss: 0.0866 - val_accuracy: 1.0000 - val_loss: 0.0553\n",
            "Epoch 103/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9821 - loss: 0.0678 - val_accuracy: 1.0000 - val_loss: 0.0546\n",
            "Epoch 104/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9944 - loss: 0.0485 - val_accuracy: 1.0000 - val_loss: 0.0536\n",
            "Epoch 105/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0651 - val_accuracy: 1.0000 - val_loss: 0.0533\n",
            "Epoch 106/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9802 - loss: 0.0687 - val_accuracy: 1.0000 - val_loss: 0.0525\n",
            "Epoch 107/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9689 - loss: 0.0914 - val_accuracy: 1.0000 - val_loss: 0.0511\n",
            "Epoch 108/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9855 - loss: 0.0731 - val_accuracy: 1.0000 - val_loss: 0.0502\n",
            "Epoch 109/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9863 - loss: 0.0627 - val_accuracy: 1.0000 - val_loss: 0.0498\n",
            "Epoch 110/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9672 - loss: 0.0868 - val_accuracy: 1.0000 - val_loss: 0.0494\n",
            "Epoch 111/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9719 - loss: 0.0726 - val_accuracy: 1.0000 - val_loss: 0.0487\n",
            "Epoch 112/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9570 - loss: 0.0908 - val_accuracy: 1.0000 - val_loss: 0.0477\n",
            "Epoch 113/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9916 - loss: 0.0540 - val_accuracy: 1.0000 - val_loss: 0.0465\n",
            "Epoch 114/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9845 - loss: 0.0590 - val_accuracy: 1.0000 - val_loss: 0.0465\n",
            "Epoch 115/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9661 - loss: 0.0697 - val_accuracy: 1.0000 - val_loss: 0.0464\n",
            "Epoch 116/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0627 - val_accuracy: 1.0000 - val_loss: 0.0455\n",
            "Epoch 117/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0654 - val_accuracy: 1.0000 - val_loss: 0.0443\n",
            "Epoch 118/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9894 - loss: 0.0520 - val_accuracy: 1.0000 - val_loss: 0.0435\n",
            "Epoch 119/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9913 - loss: 0.0588 - val_accuracy: 1.0000 - val_loss: 0.0435\n",
            "Epoch 120/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9852 - loss: 0.0581 - val_accuracy: 1.0000 - val_loss: 0.0436\n",
            "Epoch 121/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9840 - loss: 0.0503 - val_accuracy: 1.0000 - val_loss: 0.0425\n",
            "Epoch 122/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9704 - loss: 0.0726 - val_accuracy: 1.0000 - val_loss: 0.0414\n",
            "Epoch 123/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9681 - loss: 0.0880 - val_accuracy: 1.0000 - val_loss: 0.0422\n",
            "Epoch 124/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0485 - val_accuracy: 1.0000 - val_loss: 0.0416\n",
            "Epoch 125/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9854 - loss: 0.0601 - val_accuracy: 1.0000 - val_loss: 0.0411\n",
            "Epoch 126/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9884 - loss: 0.0516 - val_accuracy: 1.0000 - val_loss: 0.0402\n",
            "Epoch 127/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9487 - loss: 0.0875 - val_accuracy: 1.0000 - val_loss: 0.0431\n",
            "Epoch 128/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9842 - loss: 0.0605 - val_accuracy: 1.0000 - val_loss: 0.0412\n",
            "Epoch 129/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9888 - loss: 0.0450 - val_accuracy: 1.0000 - val_loss: 0.0395\n",
            "Epoch 130/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9962 - loss: 0.0484 - val_accuracy: 1.0000 - val_loss: 0.0382\n",
            "Epoch 131/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9537 - loss: 0.0925 - val_accuracy: 1.0000 - val_loss: 0.0413\n",
            "Epoch 132/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9881 - loss: 0.0464 - val_accuracy: 1.0000 - val_loss: 0.0380\n",
            "Epoch 133/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9901 - loss: 0.0437 - val_accuracy: 1.0000 - val_loss: 0.0385\n",
            "Epoch 134/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9600 - loss: 0.0583 - val_accuracy: 1.0000 - val_loss: 0.0377\n",
            "Epoch 135/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9735 - loss: 0.0548 - val_accuracy: 1.0000 - val_loss: 0.0377\n",
            "Epoch 136/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9857 - loss: 0.0649 - val_accuracy: 1.0000 - val_loss: 0.0371\n",
            "Epoch 137/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9763 - loss: 0.0556 - val_accuracy: 1.0000 - val_loss: 0.0370\n",
            "Epoch 138/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9882 - loss: 0.0459 - val_accuracy: 1.0000 - val_loss: 0.0369\n",
            "Epoch 139/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9631 - loss: 0.0632 - val_accuracy: 1.0000 - val_loss: 0.0361\n",
            "Epoch 140/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9556 - loss: 0.0678 - val_accuracy: 1.0000 - val_loss: 0.0356\n",
            "Epoch 141/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9509 - loss: 0.0627 - val_accuracy: 1.0000 - val_loss: 0.0363\n",
            "Epoch 142/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9797 - loss: 0.0523 - val_accuracy: 1.0000 - val_loss: 0.0363\n",
            "Epoch 143/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9543 - loss: 0.0648 - val_accuracy: 1.0000 - val_loss: 0.0348\n",
            "Epoch 144/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0551 - val_accuracy: 1.0000 - val_loss: 0.0337\n",
            "Epoch 145/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9946 - loss: 0.0384 - val_accuracy: 1.0000 - val_loss: 0.0333\n",
            "Epoch 146/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9669 - loss: 0.0599 - val_accuracy: 1.0000 - val_loss: 0.0362\n",
            "Epoch 147/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9551 - loss: 0.0735 - val_accuracy: 1.0000 - val_loss: 0.0346\n",
            "Epoch 148/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9701 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0339\n",
            "Epoch 149/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9827 - loss: 0.0368 - val_accuracy: 1.0000 - val_loss: 0.0323\n",
            "Epoch 150/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9916 - loss: 0.0500 - val_accuracy: 1.0000 - val_loss: 0.0317\n",
            "Epoch 151/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9797 - loss: 0.0430 - val_accuracy: 1.0000 - val_loss: 0.0350\n",
            "Epoch 152/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9631 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0310\n",
            "Epoch 153/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9832 - loss: 0.0380 - val_accuracy: 1.0000 - val_loss: 0.0319\n",
            "Epoch 154/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9733 - loss: 0.0535 - val_accuracy: 1.0000 - val_loss: 0.0322\n",
            "Epoch 155/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9829 - loss: 0.0373 - val_accuracy: 1.0000 - val_loss: 0.0323\n",
            "Epoch 156/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9631 - loss: 0.0595 - val_accuracy: 1.0000 - val_loss: 0.0329\n",
            "Epoch 157/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9654 - loss: 0.0647 - val_accuracy: 1.0000 - val_loss: 0.0324\n",
            "Epoch 158/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9969 - loss: 0.0337 - val_accuracy: 1.0000 - val_loss: 0.0297\n",
            "Epoch 159/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9698 - loss: 0.0483 - val_accuracy: 1.0000 - val_loss: 0.0329\n",
            "Epoch 160/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9690 - loss: 0.0545 - val_accuracy: 1.0000 - val_loss: 0.0320\n",
            "Epoch 161/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9725 - loss: 0.0460 - val_accuracy: 1.0000 - val_loss: 0.0311\n",
            "Epoch 162/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9552 - loss: 0.0611 - val_accuracy: 1.0000 - val_loss: 0.0332\n",
            "Epoch 163/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9789 - loss: 0.0445 - val_accuracy: 1.0000 - val_loss: 0.0307\n",
            "Epoch 164/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9690 - loss: 0.0436 - val_accuracy: 1.0000 - val_loss: 0.0291\n",
            "Epoch 165/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9631 - loss: 0.0655 - val_accuracy: 1.0000 - val_loss: 0.0293\n",
            "Epoch 166/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9778 - loss: 0.0475 - val_accuracy: 1.0000 - val_loss: 0.0286\n",
            "Epoch 167/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9714 - loss: 0.0566 - val_accuracy: 1.0000 - val_loss: 0.0315\n",
            "Epoch 168/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9884 - loss: 0.0487 - val_accuracy: 1.0000 - val_loss: 0.0306\n",
            "Epoch 169/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9956 - loss: 0.0210 - val_accuracy: 1.0000 - val_loss: 0.0269\n",
            "Epoch 170/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9641 - loss: 0.0649 - val_accuracy: 1.0000 - val_loss: 0.0295\n",
            "Epoch 171/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9898 - loss: 0.0545 - val_accuracy: 1.0000 - val_loss: 0.0259\n",
            "Epoch 172/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9916 - loss: 0.0343 - val_accuracy: 1.0000 - val_loss: 0.0269\n",
            "Epoch 173/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9822 - loss: 0.0561 - val_accuracy: 1.0000 - val_loss: 0.0290\n",
            "Epoch 174/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9941 - loss: 0.0297 - val_accuracy: 1.0000 - val_loss: 0.0300\n",
            "Epoch 175/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9690 - loss: 0.0521 - val_accuracy: 1.0000 - val_loss: 0.0285\n",
            "Epoch 176/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9509 - loss: 0.0689 - val_accuracy: 1.0000 - val_loss: 0.0296\n",
            "Epoch 177/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9871 - loss: 0.0393 - val_accuracy: 1.0000 - val_loss: 0.0294\n",
            "Epoch 178/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9702 - loss: 0.0589 - val_accuracy: 1.0000 - val_loss: 0.0289\n",
            "Epoch 179/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0500 - val_accuracy: 1.0000 - val_loss: 0.0289\n",
            "Epoch 180/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9946 - loss: 0.0344 - val_accuracy: 1.0000 - val_loss: 0.0289\n",
            "Epoch 181/300\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9786 - loss: 0.0618 - val_accuracy: 1.0000 - val_loss: 0.0273\n",
            "Epoch 181: early stopping\n",
            "Restoring model weights from the end of the best epoch: 171.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Callback de early stopping\n",
        "early_stop = EarlyStopping(\n",
        "    monitor='val_loss',      # Qué métrica observar\n",
        "    patience=10,             # Número de épocas sin mejora antes de detener\n",
        "    restore_best_weights=True,  # Restaurar los pesos con mejor val_loss\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Entrenar el modelo con early stopping\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=300,\n",
        "    batch_size=8,\n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stop],   # Aquí se activa\n",
        "    verbose=1\n",
        ")"
      ],
      "id": "2aqbRzeApsGk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsnhh7JqpsGk"
      },
      "source": [
        "## 6. EVALUACIÓN DEL MODELO"
      ],
      "id": "Qsnhh7JqpsGk"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1hMvOPLpsGk",
        "outputId": "8a8ab685-f399-4ed2-a323-247c64a9736c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy en test: 0.9667\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "\n",
            "Confusion Matrix and Statistics\n",
            "\n",
            "            Reference\n",
            "Prediction setosa         12         0          0     \n",
            "Prediction versicolor     0          8          0     \n",
            "Prediction virginica      0          1          9     \n",
            "\n",
            "Kappa: 0.9495\n",
            "\n",
            "Reporte de clasificación:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      setosa       1.00      1.00      1.00        12\n",
            "  versicolor       0.89      1.00      0.94         8\n",
            "   virginica       1.00      0.90      0.95        10\n",
            "\n",
            "    accuracy                           0.97        30\n",
            "   macro avg       0.96      0.97      0.96        30\n",
            "weighted avg       0.97      0.97      0.97        30\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, cohen_kappa_score\n",
        "import pandas as pd\n",
        "\n",
        "# Evaluar en el conjunto de prueba\n",
        "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Accuracy en test: {accuracy:.4f}\")\n",
        "\n",
        "# Predicciones y métricas\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Matriz de confusión con formato tipo R\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "df_cm = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
        "print(\"\\nConfusion Matrix and Statistics\\n\")\n",
        "print(\"            Reference\")\n",
        "for i, row_name in enumerate(class_names):\n",
        "    row_vals = \" \".join(f\"{val:^10}\" for val in df_cm.iloc[i])\n",
        "    print(f\"Prediction {row_name:<10} {row_vals}\")\n",
        "\n",
        "# Kappa\n",
        "kappa = cohen_kappa_score(y_true_classes, y_pred_classes)\n",
        "print(f\"\\nKappa: {kappa:.4f}\\n\")\n",
        "\n",
        "# Reporte de clasificación\n",
        "print(\"Reporte de clasificación:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=class_names))"
      ],
      "id": "W1hMvOPLpsGk"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}